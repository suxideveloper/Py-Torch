{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "366ba261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello world!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4ad714",
   "metadata": {},
   "source": [
    "Bu nvidia-smi buyrug`i GPU ni statisticasini chiqarib beradi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "755998ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 10 09:21:45 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     Off |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   44C    P8              9W /   80W |     736MiB /   6144MiB |     24%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2532      G   /usr/lib/xorg/Xorg                      274MiB |\n",
      "|    0   N/A  N/A            2839      G   /usr/bin/gnome-shell                     99MiB |\n",
      "|    0   N/A  N/A            3528      G   ...6814/usr/bin/telegram-desktop         68MiB |\n",
      "|    0   N/A  N/A            4089      G   ...ersion=20251009-010036.116000        114MiB |\n",
      "|    0   N/A  N/A            4777      G   /proc/self/exe                          150MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92a54d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu129\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97ab4d5",
   "metadata": {},
   "source": [
    "Introduction to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca772a4",
   "metadata": {},
   "source": [
    "Creating tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "143bf473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scalars, vectors, matrices, tensors\n",
    "# 0D, 1D, 2D, 3D, nD tensors\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef3a84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn Torch tensors are created using torch.tensor() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "551f2df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6adbc5e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get tensor back as Python int \n",
    "scalar.item() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9365db96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 7])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = torch.tensor([7, 7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d071cbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.ndim # this number of square brackets indicates the number of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65ceb1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector.shape    # shape of the tensor describes how many elements in each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03778415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 10]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MTRIX\n",
    "MATRIX = torch.tensor([[7, 8],\n",
    "                       [9, 10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec1c80a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim # this number of square brackets indicates the number of dimensions\n",
    "   # shape of the tensor describes how many elements in each dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b585ff6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.shape # rows, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79f25492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "008310e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[0] # first row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "378cf6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9, 10])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MATRIX[1] # second row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a4d0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2, 3],\n",
       "         [4, 5, 6],\n",
       "         [7, 8, 9]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR = torch.tensor([[[1, 2, 3],\n",
    "                        [4, 5, 6],\n",
    "                        [7, 8, 9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19cf35ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b37855d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 3])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "459881a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TENSOR[0] # first matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48f6bf",
   "metadata": {},
   "source": [
    "Random Tensors are important because the way many neural networks  learn is that tey start with tensors full of random numbers and then adjust those random numbers to better represent the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8788419b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4343, 0.9695, 0.3289, 0.2321],\n",
       "        [0.8126, 0.6510, 0.0362, 0.2700],\n",
       "        [0.8009, 0.9563, 0.1418, 0.4242]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(3, 4) # 3D tensor of random numbers between 0 and 1\n",
    "random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8607592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91fe8cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([224, 224, 3]), 3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_image_size = torch.rand(224, 224, 3) # height, width, color channels (RGB)\n",
    "random_image_size.shape , random_image_size.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecc7aad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9664, 0.0131, 0.2613, 0.2828],\n",
       "        [0.8424, 0.9553, 0.8488, 0.0924],\n",
       "        [0.5527, 0.2103, 0.2841, 0.8291]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(size=(3, 4)) # another way of creating a random tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d99a9778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a tensor of all zeros \n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f078135d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zeros * random_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e10155c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones = torch.ones(size = (3, 4))\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "796aceb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e163e93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0, 10) # deprecated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "58d03b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 2.,  3., 10.]), torch.float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([2.0, 3.0, 10.0], dtype=None)\n",
    "float_32_tensor,  float_32_tensor.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29a4c29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.]), torch.float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor = torch.tensor([3.0, 6.0, 9.0], \n",
    "                            dtype=torch.float32,\n",
    "                            device = None,\n",
    "                            requires_grad = False) # specify the datatype of a tensor upon creation\n",
    "float_tensor, float_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af06bce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3., 6., 9.], dtype=torch.float16), torch.float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor_16 = float_tensor.type(torch.float16)\n",
    "float_tensor_16, float_tensor_16.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2ce7d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 36., 81.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_tensor * float_tensor_16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aa982e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5], dtype=torch.int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor = torch.tensor([3, 4, 5], dtype = torch.int32)\n",
    "int_32_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ddbf7c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 9., 24., 45.], dtype=torch.float16)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor * float_tensor_16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1794e960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_32_tensor_new = torch.tensor([3,4,5], dtype = torch.long) # Bu variant int32 ni urniga log ni ham yozsa buladi \n",
    "int_32_tensor_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c9a0d",
   "metadata": {},
   "source": [
    "### Getting information from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61579acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2746, 0.3252, 0.4513, 0.6686],\n",
       "        [0.0333, 0.7912, 0.0650, 0.0912],\n",
       "        [0.0468, 0.0173, 0.5610, 0.6623]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_tensor = torch.rand(3,4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd976343",
   "metadata": {},
   "source": [
    "# Find out detials about some tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deaf1bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2746, 0.3252, 0.4513, 0.6686],\n",
      "        [0.0333, 0.7912, 0.0650, 0.0912],\n",
      "        [0.0468, 0.0173, 0.5610, 0.6623]])\n",
      "Datatype of tensor: torch.float32\n",
      "Shape of tensor: torch.Size([3, 4])\n",
      "Device tensor is on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(some_tensor)\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Device tensor is on: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3599b7a",
   "metadata": {},
   "source": [
    "# Manipulating Tensors (tensor  operations)\n",
    "Tensor operations include \n",
    "* Addition\n",
    "* Subtraction\n",
    "* Multiplications\n",
    "* Division\n",
    "* Matrix multiplication\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25accc64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([13, 14, 16])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 4])\n",
    "tensor + 12 \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8bad54d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 40])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10 # kupaytirish amali\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eca9d592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-9, -8, -6])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor - 10 # ayirish amali\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1464a9f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.2000, 0.4000])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor / 10 # Bulish amali \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff50dff",
   "metadata": {},
   "source": [
    "# Try out PyTorch build-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9d54d894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10, 20, 40])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(tensor, 10) # kupaytirish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddd10519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 12, 14])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(tensor, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "958117ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 4]) * tensor([1, 2, 4])\n",
      "Equals: tensor([ 1,  4, 16])\n"
     ]
    }
   ],
   "source": [
    "print(tensor , '*' , tensor)\n",
    "print(f\"Equals: {tensor * tensor }\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "640ad38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93ebce1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.55 ms, sys: 0 ns, total: 1.55 ms\n",
      "Wall time: 1.09 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "value = 0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "\n",
    "value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6118eeaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,4,5,6,7]\n",
    "for i in a:\n",
    "\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "06433c5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 384 μs, sys: 60 μs, total: 444 μs\n",
      "Wall time: 310 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "torch.matmul(tensor, tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f805dcd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(21)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor @ tensor "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550d2d1b",
   "metadata": {},
   "source": [
    "The inner dimensions must match:\n",
    "* (3, 2) @ (3, 2) won't work\n",
    "* (2, 3) @ (3, 2) will work\n",
    "* (3, 2) @ (2, 3) will work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ee879d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a45dd60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(torch.rand(2,3), torch.rand(3, 2)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc13e44e",
   "metadata": {},
   "source": [
    "# One of the most common errors in deep learning : Shape errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7a74140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapes for matrix multiplications\n",
    "tensor_A = torch.tensor([[1,2],\n",
    "                         [3,4],\n",
    "                         [5,6]])\n",
    "tensor_B = torch.tensor([[7,8],\n",
    "                         [9,19],\n",
    "                         [11,23]])\n",
    "#torch.mm(tensor_A, tesnor_B) # torch.mm is the same as torch.matmul (it's an alias for writing less code )\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1b8e7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape, tensor_B.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beb28ef",
   "metadata": {},
   "source": [
    "# To fix out tensor shape issues, we can manipulate the shape of one of our tensors useing transpose\\\n",
    "# A transpose switches the axes or dimensions of a given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a6959820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  9, 11],\n",
       "        [ 8, 19, 23]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67292715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 7,  8],\n",
       "        [ 9, 19],\n",
       "        [11, 23]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "aed23f95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.T.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "778e8cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_B.shape # transpose 3,2 ni 2, 3 ga uzgartiradi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "96563436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a17247e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shapes of tensors: tensor_A = torch.Size([3, 2]), tesnor_B = torch.Size([3, 2])\n",
      "New shapes: tesor_A = tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]]) (same shape as above), tensor_B.T = torch.Size([2, 3])\n",
      "Muplitlying: torch.Size([3, 2]) @ torch.Size([2, 3])\n",
      "Output:\n",
      " \n",
      "tensor([[ 89, 116],\n",
      "        [180, 230]])\n",
      "torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original shapes of tensors: tensor_A = {tensor_A.shape}, tesnor_B = {tensor_B.shape}\")\n",
    "print(f\"New shapes: tesor_A = {tensor_A} (same shape as above), tensor_B.T = {tensor_B.T.shape}\")\n",
    "print(f\"Muplitlying: {tensor_A.shape} @ {tensor_B.T.shape}\")\n",
    "print(\"Output:\\n \")\n",
    "output = torch.matmul(tensor_B.T, tensor_A)\n",
    "print(output)\n",
    "print(output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2e31d4bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]), torch.int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "568f3060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.min(x), x.min() # find the min\n",
    "x.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a2ee20cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(90), tensor(90))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(x), x.max() # find the max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6eaee9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(45.), tensor(45.))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(x.type(torch.float32)), x.type(torch.float32).mean() \n",
    "# Find the mean - note: the torch .mean() function requires a tensor of float32 to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e17460b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(450), tensor(450))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the sum \n",
    "torch.sum(x), x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3bdf9dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Findinf the positions of min and max \n",
    "x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e354fcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the position in tensor that has the  minimum value with argmin() -> returns index position of target tensor \n",
    "x.argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "38081f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find the position in tensor that has the maximum value with argmax()\n",
    "x.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "277614fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(90)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e882f0",
   "metadata": {},
   "source": [
    "# Reshaping, stacking, squeezing and unsqueezing tensors\n",
    "* Reshaping - reshapes an input tensor to a defined shape\n",
    "* View -Return a view of an input tensor of certain shape but keep the same memory as the original tensor\n",
    "* Stacking - combine multipe  vtack tesnors on top of each other (vstack) or side by side  hstack\n",
    "* Squeeze - removes all one dimensions from a tensor\n",
    "* Unsqueeze - add a one dinstions to a target tensor\n",
    "\n",
    "* Permute - return a view of the input with dimenstions permuted (swapped) in certain way  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "67fb4da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.]), torch.Size([9]))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1., 10.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "29c5b44d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add an extra dimension\n",
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1, 9)\n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "40813e9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped = x.reshape(1, 9) # Add an extra dimension \n",
    "x_reshaped, x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29edff1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]]), torch.Size([1, 9]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(1, 9)  # Change the view \n",
    "z, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1266b9d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]]),\n",
       " tensor([5., 2., 3., 4., 5., 6., 7., 8., 9.]))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z[:, 0] = 5\n",
    "z, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eeb282d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
       "        [5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack tensor on top of each other \\\n",
    "x_stacked = torch.stack([x,x,x,x], dim = 0)\n",
    "x_stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a4c91d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# troch.squeeze()- remove all single dimensions from a target tensor\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fbe3233c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 1, 2])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "x = torch.zeros(2, 1, 2, 1, 2)\n",
    "x.size\n",
    "y = torch.squeeze(x)\n",
    "y.size()\n",
    "y = torch.squeeze(x, 0)\n",
    "y.size()\n",
    "y = torch.squeeze(x, 1)\n",
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c888cbf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "95e9b3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "565df034",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_squeezed = x_reshaped.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4f183334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_reshaped.squeeze().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96120d0b",
   "metadata": {},
   "source": [
    "# torch.unsqueeze() - adds a single dimension to a target tesnor at a specific dim (dimenson)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26d2356e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 2., 3., 4., 5., 6., 7., 8., 9.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unsqueezed = x_squeezed.unsqueeze(dim = 0)\n",
    "x_unsqueezed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2c05d65b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[3.2899e-01, 9.4775e-01, 4.0468e-01,  ..., 1.6546e-01,\n",
       "           1.7340e-01, 8.1469e-01],\n",
       "          [4.9219e-01, 2.4427e-01, 7.8016e-02,  ..., 2.8733e-01,\n",
       "           8.1879e-01, 9.5867e-01],\n",
       "          [7.9610e-01, 7.8064e-01, 9.1931e-01,  ..., 7.6977e-01,\n",
       "           4.3605e-01, 8.1612e-01],\n",
       "          ...,\n",
       "          [1.7337e-01, 5.5090e-01, 4.1423e-01,  ..., 1.4201e-01,\n",
       "           9.7185e-04, 5.3041e-01],\n",
       "          [6.3797e-01, 2.0331e-01, 1.9911e-01,  ..., 7.2315e-01,\n",
       "           1.7996e-01, 5.3905e-01],\n",
       "          [5.6692e-01, 2.7416e-01, 4.1924e-01,  ..., 9.9414e-01,\n",
       "           6.7729e-01, 1.2631e-01]],\n",
       " \n",
       "         [[5.8108e-01, 1.8053e-01, 5.8499e-01,  ..., 3.8907e-01,\n",
       "           5.8767e-01, 7.3375e-01],\n",
       "          [1.8144e-01, 5.6621e-01, 7.6133e-01,  ..., 5.5237e-01,\n",
       "           3.3023e-01, 6.3567e-01],\n",
       "          [5.6410e-01, 7.6364e-01, 6.0699e-01,  ..., 2.6104e-01,\n",
       "           6.9781e-01, 5.0791e-01],\n",
       "          ...,\n",
       "          [8.5097e-01, 4.0093e-01, 6.4082e-01,  ..., 1.0440e-01,\n",
       "           2.2181e-01, 6.4669e-01],\n",
       "          [4.8644e-01, 6.3083e-01, 4.5868e-01,  ..., 7.8164e-01,\n",
       "           4.8889e-02, 5.2571e-01],\n",
       "          [5.6312e-01, 4.8706e-01, 9.4504e-02,  ..., 9.9256e-01,\n",
       "           6.9225e-01, 5.4262e-01]],\n",
       " \n",
       "         [[2.8503e-01, 9.6421e-01, 9.7073e-01,  ..., 5.6093e-01,\n",
       "           9.4672e-01, 7.5164e-01],\n",
       "          [6.8894e-01, 7.9829e-01, 1.3165e-01,  ..., 3.4324e-01,\n",
       "           9.7834e-01, 7.5316e-01],\n",
       "          [3.1790e-01, 8.5819e-01, 8.6084e-01,  ..., 9.7195e-01,\n",
       "           8.4691e-01, 2.8117e-01],\n",
       "          ...,\n",
       "          [4.7386e-01, 2.6266e-01, 2.0819e-01,  ..., 8.2958e-01,\n",
       "           5.3498e-01, 1.5460e-01],\n",
       "          [8.7848e-01, 4.1388e-01, 5.2723e-01,  ..., 9.9884e-02,\n",
       "           4.7964e-01, 1.1236e-01],\n",
       "          [4.0516e-01, 3.4927e-01, 5.5440e-01,  ..., 2.1965e-01,\n",
       "           7.1799e-01, 2.1474e-01]]]),\n",
       " torch.Size([3, 224, 224]),\n",
       " torch.Size([224, 224, 3]))"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.permute - rearrange the dimensions of a target tensor in a specified order \n",
    "x_original = torch.rand(size = (224, 224,3)) \n",
    "x_permuted = x_original.permute(2, 0, 1)    # shift axis 0->1, 1>2, 2>0\n",
    "x_permuted, x_permuted.shape, x_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c2bc3fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[3.2899e-01, 5.8108e-01, 2.8503e-01],\n",
       "         [9.4775e-01, 1.8053e-01, 9.6421e-01],\n",
       "         [4.0468e-01, 5.8499e-01, 9.7073e-01],\n",
       "         ...,\n",
       "         [1.6546e-01, 3.8907e-01, 5.6093e-01],\n",
       "         [1.7340e-01, 5.8767e-01, 9.4672e-01],\n",
       "         [8.1469e-01, 7.3375e-01, 7.5164e-01]],\n",
       "\n",
       "        [[4.9219e-01, 1.8144e-01, 6.8894e-01],\n",
       "         [2.4427e-01, 5.6621e-01, 7.9829e-01],\n",
       "         [7.8016e-02, 7.6133e-01, 1.3165e-01],\n",
       "         ...,\n",
       "         [2.8733e-01, 5.5237e-01, 3.4324e-01],\n",
       "         [8.1879e-01, 3.3023e-01, 9.7834e-01],\n",
       "         [9.5867e-01, 6.3567e-01, 7.5316e-01]],\n",
       "\n",
       "        [[7.9610e-01, 5.6410e-01, 3.1790e-01],\n",
       "         [7.8064e-01, 7.6364e-01, 8.5819e-01],\n",
       "         [9.1931e-01, 6.0699e-01, 8.6084e-01],\n",
       "         ...,\n",
       "         [7.6977e-01, 2.6104e-01, 9.7195e-01],\n",
       "         [4.3605e-01, 6.9781e-01, 8.4691e-01],\n",
       "         [8.1612e-01, 5.0791e-01, 2.8117e-01]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.7337e-01, 8.5097e-01, 4.7386e-01],\n",
       "         [5.5090e-01, 4.0093e-01, 2.6266e-01],\n",
       "         [4.1423e-01, 6.4082e-01, 2.0819e-01],\n",
       "         ...,\n",
       "         [1.4201e-01, 1.0440e-01, 8.2958e-01],\n",
       "         [9.7185e-04, 2.2181e-01, 5.3498e-01],\n",
       "         [5.3041e-01, 6.4669e-01, 1.5460e-01]],\n",
       "\n",
       "        [[6.3797e-01, 4.8644e-01, 8.7848e-01],\n",
       "         [2.0331e-01, 6.3083e-01, 4.1388e-01],\n",
       "         [1.9911e-01, 4.5868e-01, 5.2723e-01],\n",
       "         ...,\n",
       "         [7.2315e-01, 7.8164e-01, 9.9884e-02],\n",
       "         [1.7996e-01, 4.8889e-02, 4.7964e-01],\n",
       "         [5.3905e-01, 5.2571e-01, 1.1236e-01]],\n",
       "\n",
       "        [[5.6692e-01, 5.6312e-01, 4.0516e-01],\n",
       "         [2.7416e-01, 4.8706e-01, 3.4927e-01],\n",
       "         [4.1924e-01, 9.4504e-02, 5.5440e-01],\n",
       "         ...,\n",
       "         [9.9414e-01, 9.9256e-01, 2.1965e-01],\n",
       "         [6.7729e-01, 6.9225e-01, 7.1799e-01],\n",
       "         [1.2631e-01, 5.4262e-01, 2.1474e-01]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_original"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07868ce",
   "metadata": {},
   "source": [
    "## Indexing (selecting data from tensor)\n",
    "Indexing with PyTorch is simmilar to indexing with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b1a52229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [4, 5, 6],\n",
       "          [7, 8, 9]]]),\n",
       " torch.Size([1, 3, 3]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9d0c911e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's index on  our new tensor\n",
    "x[0][0]\n",
    "# x[0], x[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3687efee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's index on the most inner bracket(last dimension)\\\n",
    "x[0][2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c40c007f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3]]), tensor([[2, 5, 8]]))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 0], x[:, :, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fb43ff28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be1d9ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97fe6b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9)\n",
      "tensor([[3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Index on x to return 9\n",
    "print(x[0][2][2])\n",
    "\n",
    "# Index on x to retur 3, 6, 9\n",
    "print(x[:, :, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135b8f41",
   "metadata": {},
   "source": [
    "NumPy is a popular scientific Python numerical computing library \n",
    "* And because of this, PyTorch has functionality to interact with it.\n",
    "\n",
    "\n",
    "* Data in NumPy, want in PyTorch tensor-> torch.from_numpy(ndarray)\n",
    "* PyTorch tensor -> NumPy -> torch.Tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "63791a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy array to tensor\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array)\n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e34a25e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4af93722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6329eda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1.0, 8.0).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "01fb336a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.from_numpy(array).type(torch.float32)\n",
    "tensor, tensor.dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0947020e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 3., 4., 5., 6., 7., 8.]), tensor([1., 2., 3., 4., 5., 6., 7.]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = array + 1 \n",
    "array, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "01c8132f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 2., 3., 4., 5., 6., 7.]),\n",
       " array([1., 2., 3., 4., 5., 6., 7.], dtype=float32))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor to NumPy\n",
    "tesnor = torch.ones(7)\n",
    "numpy_tensor = tensor.numpy()\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "20150dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2., 3., 4., 5., 6., 7., 8.]),\n",
       " array([1., 2., 3., 4., 5., 6., 7.], dtype=float32))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Change the tensor, what happens to \"numpy_tensor\"?\n",
    "tensor = tensor + 1\n",
    "tensor, numpy_tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d80c6990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5072, 0.6821, 0.0733],\n",
       "        [0.1940, 0.3015, 0.6615],\n",
       "        [0.5035, 0.9242, 0.3204]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64c3ce0",
   "metadata": {},
   "source": [
    "# Learn PyTorch reproducebility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4610fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A rand tensor: tensor([[0.3402, 0.8951, 0.2575, 0.8008],\n",
      "        [0.5195, 0.9029, 0.6219, 0.3573],\n",
      "        [0.0676, 0.9377, 0.6732, 0.2072]]), \n",
      " B rand tensor: tensor([[0.9292, 0.7267, 0.4256, 0.4171],\n",
      "        [0.5835, 0.8399, 0.9550, 0.0378],\n",
      "        [0.2283, 0.9842, 0.8138, 0.0697]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "rand_tensor_A = torch.rand(3, 4)\n",
    "rand_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f\"A rand tensor: {rand_tensor_A}, \\n B rand tensor: {rand_tensor_B}\")\n",
    "print(rand_tensor_A == rand_tensor_B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "61ecaad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_c = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "random_tensor_d = torch.rand(3, 4)\n",
    "\n",
    "\n",
    "print(random_tensor_c)\n",
    "print(random_tensor_d)\n",
    "\n",
    "print(random_tensor_c == random_tensor_d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa04f6da",
   "metadata": {},
   "source": [
    "# Running tensors and PyTorch objects on the GPUs (and makeing faster computation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e5070edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU = faster computation on numbers, thanks to CUDA + NVIDIA hardware + PyTorch working behind the scenes to make everythibg hunky dory(good) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b4d06cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1. getting a GPU\n",
    "\n",
    "# 1. Easiest - Use Google Colab for a free GPU (options to upgrade as well)\n",
    "# 2. Use your own GPU - takes a little bit of setup and requires the investment of purchasing a GPU, there are lots of options...\n",
    "# tim dettmeres gpu\n",
    "# 3. Use cloud computing - GCP, AWS, Azure, these services allow you to rent computers on the cloud and access them"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c708839",
   "metadata": {},
   "source": [
    "## For 2, 3 PyTorch + GPU drivers (CUDA) takes a little bit of setting up, to do this, refer to PyTorch setup documentation: it https://pytorch.org/get-started/locally/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9c11544c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct 10 09:22:17 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.65.06              Driver Version: 580.65.06      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1660 Ti     Off |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   45C    P8              7W /   80W |     720MiB /   6144MiB |      5%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2532      G   /usr/lib/xorg/Xorg                      274MiB |\n",
      "|    0   N/A  N/A            2839      G   /usr/bin/gnome-shell                     99MiB |\n",
      "|    0   N/A  N/A            3528      G   ...6814/usr/bin/telegram-desktop         68MiB |\n",
      "|    0   N/A  N/A            4089      G   ...ersion=20251009-010036.116000        114MiB |\n",
      "|    0   N/A  N/A            4777      G   /proc/self/exe                          134MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9450de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e2b66db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0+cu129'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "de98ec98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device  = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c60cfd21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of devices \n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0f039e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) cpu\n"
     ]
    }
   ],
   "source": [
    "# Putting tensors (and models) on the GPU\n",
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(tensor, tensor.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5c4d8561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move tensor to GPU ( if available)\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "649a6ef8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[123]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Moving tensors back to the CPU\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# If tensor is on GPU, can't transform it to NumPy \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mtensor_on_gpu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# Moving tensors back to the CPU\n",
    "# If tensor is on GPU, can't transform it to NumPy \n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63254a7f",
   "metadata": {},
   "source": [
    "# To fix the GPU tensorwith NumPy issue we can first set it to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ffde2f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_run_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_run_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e286d644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7e538eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_on_gpu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
